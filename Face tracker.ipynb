{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import face_recognition  # <-- Add this import\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The required files for using this code**\n",
    "\n",
    "1. deploy.prototxt \"https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt\"\n",
    "2. res10_300x300_ssd_iter_140000.caffemodel \"https://github.com/keyurr2/face-detection/blob/master/res10_300x300_ssd_iter_140000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     exit()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcapture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define your name\n",
    "YOUR_NAME = \"king\"  # Change this to your actual name\n",
    "\n",
    "# Provide correct paths to model files\n",
    "MODEL_PATH = r\"C:\\Users\\sfazeli\\Downloads\\Face tracker\"  # Change this if needed\n",
    "config_file = os.path.join(MODEL_PATH, \"deploy.prototxt\")\n",
    "model_file = os.path.join(MODEL_PATH, \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "# Load deep learning model for face detection\n",
    "net = cv2.dnn.readNetFromCaffe(config_file, model_file)\n",
    "\n",
    "# Initialize dlib tracker\n",
    "tracker = dlib.correlation_tracker()\n",
    "trackingFace = False  # Whether we are tracking your face\n",
    "savedFaceEncoding = None  # Store your face encoding\n",
    "\n",
    "# Initialize webcam\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to blob for deep learning model\n",
    "    h, w = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    if not trackingFace:\n",
    "        # Detect faces using deep learning\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "\n",
    "        maxConfidence = 0\n",
    "        yourFace = None\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                box = detections[0, 0, i, 3:7] * [w, h, w, h]\n",
    "                x, y, x2, y2 = box.astype(\"int\")\n",
    "\n",
    "                # Track the face with the highest confidence (assuming it's yours)\n",
    "                if confidence > maxConfidence:\n",
    "                    yourFace = (x, y, x2, y2)\n",
    "                    maxConfidence = confidence\n",
    "\n",
    "        # If a face is detected, initialize tracker\n",
    "        if yourFace:\n",
    "            x, y, x2, y2 = yourFace\n",
    "            tracker.start_track(frame, dlib.rectangle(x, y, x2, y2))\n",
    "            trackingFace = True\n",
    "\n",
    "    else:\n",
    "        # Update tracker\n",
    "        tracker.update(frame)\n",
    "        pos = tracker.get_position()\n",
    "\n",
    "        # Get coordinates of tracked face\n",
    "        x, y, x2, y2 = int(pos.left()), int(pos.top()), int(pos.right()), int(pos.bottom())\n",
    "\n",
    "        # Draw tracking box\n",
    "        cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Display confidence score and name\n",
    "        text = f\"{YOUR_NAME} ({maxConfidence*100:.2f}%)\"\n",
    "        cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow(\"AI-Powered Face Tracker\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Individually for your face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face of King saved for tracking!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Draw tracking box\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Display confidence score and name\u001b[39;00m\n\u001b[0;32m     97\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYOUR_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxConfidence\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define your name\n",
    "YOUR_NAME = \"King\"  # This variable stores your name, which will be displayed when your face is detected.\n",
    "\n",
    "# Provide correct paths to model files\n",
    "MODEL_PATH = r\"C:\\Users\\sfazeli\\Downloads\\Face tracker\"  # Specifies the folder where the face detection model files are stored.\n",
    "config_file = os.path.join(MODEL_PATH, \"deploy.prototxt\") # Specifies the path to the prototxt file.\n",
    "model_file = os.path.join(MODEL_PATH, \"res10_300x300_ssd_iter_140000.caffemodel\") # Specifies the path to the caffemodel file.\n",
    "\n",
    "# Load deep learning model for face detection\n",
    "net = cv2.dnn.readNetFromCaffe(config_file, model_file) # Loads the pre-trained deep learning model for face detection using OpenCV's dnn module.\n",
    "\n",
    "# Initialize dlib tracker\n",
    "tracker = dlib.correlation_tracker() # dlib.correlation_tracker() is used to follow your face after detection\n",
    "trackingFace = False  #  Boolean flag to check if tracking is active.\n",
    "savedFaceEncoding = None  # Stores the unique encoding of your face.\n",
    "savedBoundingBox = None  # Store your bounding box. Stores the coordinates of the tracked face.\n",
    "\n",
    "# Initialize webcam\n",
    "capture = cv2.VideoCapture(0) # ✔ Opens the webcam to start capturing video frames.\n",
    "\n",
    "if not capture.isOpened(): # ✔ Checks if the webcam is opened successfully.\n",
    "    print(\"Error: Could not open webcam.\") # ✔ Prints an error message if the webcam fails to open.\n",
    "    exit()\n",
    "\n",
    "while True: # ✔ Starts an infinite loop to capture video frames from the webcam.\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to blob for deep learning model\n",
    "    h, w = frame.shape[:2] # ✔ Extracts the height and width of the frame.\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0)) # ✔ Converts the frame to a blob format for the deep learning model.Normalizes pixel values by subtracting (104.0, 177.0, 123.0) (mean subtraction).\n",
    "\n",
    "    if not trackingFace:\n",
    "        # Detect faces using deep learning\n",
    "        net.setInput(blob) #Sends the processed image (blob) to the deep learning model.\n",
    "        detections = net.forward() # Detects faces in the frame using the deep learning model.\n",
    "\n",
    "        maxConfidence = 0\n",
    "        yourFace = None # Stores the coordinates of your face.\n",
    "        bestEncoding = None # Stores the encoding of the best match.\n",
    "\n",
    "        for i in range(detections.shape[2]): # Iterates over the detected faces.\n",
    "            confidence = detections[0, 0, i, 2] # Extracts the confidence score of the detected face.\n",
    "            if confidence > 0.7:  # Confidence threshold increased for better accuracy\n",
    "                box = detections[0, 0, i, 3:7] * [w, h, w, h] # Extracts the bounding box coordinates of the detected face.\n",
    "                x, y, x2, y2 = box.astype(\"int\") # Converts the coordinates to integers.\n",
    "\n",
    "                # Extract the face ROI and compute encoding\n",
    "                faceROI = frame[y:y2, x:x2] # Extracts the face region of interest (ROI) from the frame.\n",
    "                \n",
    "                if faceROI.shape[0] > 0 and faceROI.shape[1] > 0: # Checks if the face ROI is valid.\n",
    "                    rgbFace = cv2.cvtColor(faceROI, cv2.COLOR_BGR2RGB) # Converts the face ROI to RGB format.\n",
    "                    encodings = face_recognition.face_encodings(rgbFace) # Computes the face encoding using face_recognition library.\n",
    "\n",
    "                    if encodings:\n",
    "                        faceEncoding = encodings[0]  # Take the first detected face\n",
    "\n",
    "                        # If this is the first time, store your face encoding\n",
    "                        if savedFaceEncoding is None:\n",
    "                            savedFaceEncoding = faceEncoding\n",
    "                            savedBoundingBox = (x, y, x2, y2)\n",
    "                            print(f\"Face of {YOUR_NAME} saved for tracking!\")\n",
    "\n",
    "                        # Compare this face with your stored face\n",
    "                        match = face_recognition.compare_faces([savedFaceEncoding], faceEncoding)[0]\n",
    "\n",
    "                        if match and confidence > maxConfidence:\n",
    "                            yourFace = (x, y, x2, y2)\n",
    "                            maxConfidence = confidence\n",
    "                            bestEncoding = faceEncoding # Store the best encoding\n",
    "\n",
    "        # If a matching face is detected, initialize tracker\n",
    "        if yourFace:\n",
    "            x, y, x2, y2 = yourFace\n",
    "            tracker.start_track(frame, dlib.rectangle(x, y, x2, y2)) # Initializes the dlib tracker with the bounding box of the detected face.\n",
    "            trackingFace = True # Sets the trackingFace flag to True to indicate that tracking is active.\n",
    "            savedBoundingBox = (x, y, x2, y2)\n",
    "\n",
    "    else:\n",
    "        # Update tracker\n",
    "        tracker.update(frame) # Updates the tracker with the new frame.\n",
    "        pos = tracker.get_position() # Gets the position of the tracked face.\n",
    "\n",
    "        # Get coordinates of tracked face\n",
    "        x, y, x2, y2 = int(pos.left()), int(pos.top()), int(pos.right()), int(pos.bottom())\n",
    "\n",
    "        # If tracking drifts too much, reset tracking\n",
    "        if abs(x - savedBoundingBox[0]) > 50 or abs(y - savedBoundingBox[1]) > 50:\n",
    "            trackingFace = False\n",
    "            continue\n",
    "\n",
    "        # Draw tracking box\n",
    "        cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Display confidence score and name\n",
    "        text = f\"{YOUR_NAME} ({maxConfidence*100:.2f}%)\"\n",
    "        cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2) # Displays the name and confidence score of the detected face.\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow(\"AI-Powered Face Tracker\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
